{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chess-piece-recognize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPQCmulMA/hnQh1220vVtQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Errleng/chess-position-recognizer/blob/main/chess_piece_recognize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRrWJfTXd6rL"
      },
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "mount_path = '/content/google-drive'\n",
        "drive.mount(mount_path)\n",
        "content_path = mount_path + '/MyDrive/colab-files/'\n",
        "chess_pos_path = content_path + 'chess-positions/dataset/'\n",
        "chess_pieces_path = content_path + 'chess-pieces/'\n",
        "utils_path = content_path + 'utils/tensorflow_chessbot-chessfenbot/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H51ru0FLem4b"
      },
      "source": [
        "# for local dataset\n",
        "content_path = ''\n",
        "chess_pos_path = content_path + 'dataset/'\n",
        "chess_pieces_path = content_path + 'chess-pieces/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWQ0GhB9pt1V"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/google-drive/MyDrive/colab-files/utils/kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Q7O6WKqYBS"
      },
      "source": [
        "! kaggle datasets download -p /content/google-drive/MyDrive/colab-files/chess-positions -d koryakinp/chess-positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge02mD3srcE3"
      },
      "source": [
        "!unzip /content/google-drive/MyDrive/colab-files/chess-positions/chess-positions.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj5GkXySdGaL"
      },
      "source": [
        "# download directly here instead of Google Drive\n",
        "!kaggle datasets download -d koryakinp/chess-positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCYD_2OCdM2-"
      },
      "source": [
        "!unzip chess-positions.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27lIhftdW_3Z"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "FEN_CHAR_STRING = '1KQRBNPkqrbnp'\n",
        "class_names = ['Empty',\n",
        "               'White King', 'White Queen', 'White Rook',\n",
        "               'White Bishop', 'White Knight', 'White Pawn',\n",
        "               'Black King', 'Black Queen', 'Black Rook',\n",
        "               'Black Bishop', 'Black Knight', 'Black Pawn']\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUEnD5vehxZ"
      },
      "source": [
        "def generate_random_fen():\n",
        "  default_info = ' w KQkq - 0 1'\n",
        "  fen_square_chars = list(FEN_CHAR_STRING)\n",
        "  fen = []\n",
        "  for i in range(8):\n",
        "    if i > 0:\n",
        "      fen.append('/')\n",
        "    fen += np.random.choice(fen_square_chars, 8).tolist()\n",
        "  fen = ''.join(fen) + default_info\n",
        "  return fen\n",
        "print(f'Random FEN: {generate_random_fen()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avDbViS6hWpB"
      },
      "source": [
        "def get_label_from_fen(fen, rank, file):\n",
        "  piece_letter = None\n",
        "  remaining_rank, remaining_file = rank, file\n",
        "  for i in range(len(fen)):\n",
        "    if remaining_rank > 0:\n",
        "      if fen[i] == '/':\n",
        "        remaining_rank -= 1\n",
        "    else:\n",
        "      if remaining_file == 0:\n",
        "        if fen[i].isdigit():\n",
        "          piece_letter = '1'\n",
        "        else:\n",
        "          piece_letter = fen[i]\n",
        "        break\n",
        "      if fen[i].isdigit():\n",
        "        empty_squares = int(fen[i])\n",
        "        if empty_squares > remaining_file:\n",
        "          piece_letter = '1'\n",
        "          break\n",
        "        else:\n",
        "          remaining_file -= empty_squares\n",
        "      else:\n",
        "        remaining_file -= 1\n",
        "  piece_index = FEN_CHAR_STRING.find(piece_letter)\n",
        "  # if piece_letter != '1':\n",
        "  #   print(f'rank {rank} file {file} piece letter {piece_letter} with index {piece_index} at {fen}')\n",
        "  return piece_index\n",
        "\n",
        "def process_position(pos_image, fen):\n",
        "  square_dim = 400//8\n",
        "  squares = []\n",
        "  labels = []\n",
        "  parsed_fen = fen.replace('-', '/')\n",
        "  for i in range(8):\n",
        "    x_offset = i * square_dim\n",
        "    for j in range(8):\n",
        "      y_offset = j * square_dim\n",
        "      square_image = pos_image[x_offset:x_offset + square_dim,\n",
        "                                y_offset:y_offset + square_dim]\n",
        "      square_image = cv2.cvtColor(square_image, cv2.COLOR_BGR2GRAY)                      \n",
        "      squares.append(square_image)\n",
        "      label = get_label_from_fen(parsed_fen, i, j)\n",
        "      labels.append(label)\n",
        "      # if label != 0:\n",
        "      #   print(label, class_names[label], i, j, fen)\n",
        "      #   cv2_imshow(square_image)\n",
        "  return squares, labels\n",
        "\n",
        "def write_squares_labels(output_path, pos_image, fen):\n",
        "  square_dim = 400//8\n",
        "  parsed_fen = fen.replace('-', '/')\n",
        "  for i in range(8):\n",
        "    x_offset = i * square_dim\n",
        "    for j in range(8):\n",
        "      y_offset = j * square_dim\n",
        "      square_image = pos_image[x_offset:x_offset + square_dim,\n",
        "                                y_offset:y_offset + square_dim]\n",
        "      square_image = cv2.cvtColor(square_image, cv2.COLOR_BGR2GRAY)\n",
        "      label = get_label_from_fen(parsed_fen, i, j)\n",
        "      filename = f'{output_path}{fen}-fen-{i}-{j}-{label}.jpeg'\n",
        "      cv2.imwrite(filename, square_image)\n",
        "\n",
        "def write_images_labels(input_path, output_path, max_files=100, overwrite=False):\n",
        "  count = 1\n",
        "  path_in = Path(input_path)\n",
        "  path_out = Path(output_path)\n",
        "  path_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  existing_files = set()\n",
        "  for file in path_out.iterdir():\n",
        "    fen = re.search('^(.*)-fen-.*\\.jpeg$', file.name).group(1)\n",
        "    if fen not in existing_files:\n",
        "      existing_files.add(fen)\n",
        "\n",
        "  last_time = time.time()\n",
        "  for file in path_in.iterdir():\n",
        "    if count > max_files:\n",
        "      break\n",
        "\n",
        "    if time.time() - last_time > 10:\n",
        "      last_time = time.time()\n",
        "      print(f'Wrote {count} files from {input_path} to {output_path}')\n",
        "\n",
        "    fen = re.search('^(.*)\\.jpeg$', file.name).group(1)\n",
        "\n",
        "    if not overwrite and fen in existing_files:\n",
        "      continue\n",
        "\n",
        "    image_path = input_path + file.name\n",
        "    image = cv2.imread(image_path)    \n",
        "    write_squares_labels(output_path, image, fen)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "def get_images_labels_from_images(path, max_files=100):\n",
        "  count = 1\n",
        "  images, labels = [], []\n",
        "  path_obj = Path(path)\n",
        "  for file in path_obj.iterdir():\n",
        "    if count > max_files:\n",
        "      break\n",
        "\n",
        "    image_path = path + file.name\n",
        "    image = cv2.imread(image_path)\n",
        "    fen = re.search('^(.*)\\.jpeg$', file.name).group(1)\n",
        "    square_images, square_labels = process_position(image, fen)\n",
        "\n",
        "    images += square_images\n",
        "    labels += square_labels\n",
        "    count += 1\n",
        "  return np.array(images), np.array(labels)\n",
        "\n",
        "def get_images_labels(path, max_files=100):\n",
        "  count = 1\n",
        "  images, labels = [], []\n",
        "  path_obj = Path(path)\n",
        "  for file in path_obj.iterdir():\n",
        "    if count > max_files:\n",
        "      break\n",
        "    image_path = path + file.name\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    label = int(re.search('^.*-(\\d+)\\.jpeg$', file.name).group(1))\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "    count += 1\n",
        "  return np.array(images), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNFMVwgWovha"
      },
      "source": [
        "write_images_labels(chess_pos_path + 'train/', chess_pieces_path + 'train/', 1000)\n",
        "write_images_labels(chess_pos_path + 'test/', chess_pieces_path + 'test/', 5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpckfMNOPeTA"
      },
      "source": [
        "train_images, train_labels = get_images_labels(chess_pieces_path + 'train/', 100000)\n",
        "test_images, test_labels = get_images_labels(chess_pieces_path + 'test/', 100000)\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIlWerjeP3Vn"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3T2RXwBQJXc"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(f'{train_labels[i]} {class_names[train_labels[i]]}')\n",
        "    # plt.xlabel(class_names[np.where(train_labels[i] == 1)[0][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaT_SUjtSBxZ"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(50, 50)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(13)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXorJ7cTA8g"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpEzu2CZTm6r"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epu8oVGYiKGw"
      },
      "source": [
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PXQB2I3TtNk"
      },
      "source": [
        "fen_chars = list(FEN_CHAR_STRING)\n",
        "\n",
        "num_to_show = 100\n",
        "width = 5\n",
        "height = -(-num_to_show // width)\n",
        "\n",
        "plt.figure(figsize=(10, 2 * height))\n",
        "for i in range(min(num_to_show, len(predictions))):\n",
        "  index = np.random.randint(0, len(predictions))\n",
        "  p = predictions[index]\n",
        "  img = test_images[i]\n",
        "\n",
        "  pred = np.argmax(p)\n",
        "  pred_confidence = np.max(predictions[index])\n",
        "  pred_name = class_names[pred]\n",
        "  actual_name = class_names[test_labels[index]]\n",
        "\n",
        "  item_label = f'Predict: {100 * pred_confidence:2.0f}% {pred_name}\\nAnswer: {actual_name}'\n",
        "\n",
        "  plt.subplot(height, width, i+1)\n",
        "  plt.subplots_adjust(wspace=1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(test_images[index], cmap=plt.cm.binary)\n",
        "  plt.xlabel(item_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}